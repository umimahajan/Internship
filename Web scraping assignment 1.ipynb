{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Write a python program to display all the header tags from wikipedia.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in c:\\users\\hp\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.24.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests) (1.25.11)\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "\n",
    "page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Header tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Welcome to Wikipedia',\n",
       " \"From today's featured article\",\n",
       " 'Did you know\\xa0...',\n",
       " 'In the news',\n",
       " 'On this day',\n",
       " \"Today's featured picture\",\n",
       " 'Other areas of Wikipedia',\n",
       " \"Wikipedia's sister projects\",\n",
       " 'Wikipedia languages']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "header = []\n",
    "\n",
    "for i in soup.find_all('span',class_=\"mw-headline\"):\n",
    "    header.append(i.text)\n",
    "    \n",
    "header    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Header tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Welcome to Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From today's featured article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Did you know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In the news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On this day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Today's featured picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Other areas of Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wikipedia's sister projects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wikipedia languages</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Header tags\n",
       "0           Welcome to Wikipedia\n",
       "1  From today's featured article\n",
       "2               Did you know ...\n",
       "3                    In the news\n",
       "4                    On this day\n",
       "5       Today's featured picture\n",
       "6       Other areas of Wikipedia\n",
       "7    Wikipedia's sister projects\n",
       "8            Wikipedia languages"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.DataFrame({\"Header tags\":header})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. name, rating, year of release)\n",
    "and make data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "Movie=requests.get('https://www.imdb.com/list/ls055592025/?sort=user_rating,desc&st_dt=&mode=detail&page=1')\n",
    "Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name of movies</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Release Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Lord of the Rings: The Return of the King</td>\n",
       "      <td>9</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Godfather Part II</td>\n",
       "      <td>9</td>\n",
       "      <td>1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>9</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Yankee Doodle Dandy</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Wuthering Heights</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>American Graffiti</td>\n",
       "      <td>7.4</td>\n",
       "      <td>1973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Terms of Endearment</td>\n",
       "      <td>7.4</td>\n",
       "      <td>1983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>An American in Paris</td>\n",
       "      <td>7.2</td>\n",
       "      <td>1951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   name of movies Ratings Release Date\n",
       "0                        The Shawshank Redemption     9.3         1994\n",
       "1                                   The Godfather     9.2         1972\n",
       "2   The Lord of the Rings: The Return of the King       9         2003\n",
       "3                           The Godfather Part II       9         1974\n",
       "4                                Schindler's List       9         1993\n",
       "..                                            ...     ...          ...\n",
       "95                            Yankee Doodle Dandy     7.6         1942\n",
       "96                              Wuthering Heights     7.5         1939\n",
       "97                              American Graffiti     7.4         1973\n",
       "98                            Terms of Endearment     7.4         1983\n",
       "99                           An American in Paris     7.2         1951\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "Movie=BeautifulSoup(Movie.content)\n",
    "\n",
    "\n",
    "\n",
    "movie_name = []\n",
    "\n",
    "row=Movie.find_all('h3',class_=\"lister-item-header\")\n",
    "\n",
    "for i in row:\n",
    "    for f in i('a'):\n",
    "        movie_name.append(f.text)\n",
    "rating= []\n",
    "\n",
    "for i in Movie.find_all('div',class_=\"ipl-rating-star small\"):\n",
    "    rating.append(i.text.replace('\\n',''))\n",
    "\n",
    "release_data=[]    \n",
    "    \n",
    "for i in Movie.find_all('span',\"lister-item-year text-muted unbold\"):\n",
    "    release_data.append(i.text.replace(\"(\",\"\").replace(\")\",\"\"))\n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.DataFrame({\"name of movies\":movie_name,\"Ratings\":rating,\"Release Date\":release_data})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. name, rating, year of release) and make data frame. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "indian_Movie=requests.get('https://www.imdb.com/list/ls056092300/')\n",
    "indian_Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name of movies</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Release Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ship of Theseus</td>\n",
       "      <td>8</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iruvar</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kaagaz Ke Phool</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lagaan: Once Upon a Time in India</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pather Panchali</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Apur Sansar</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Kanchivaram</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Monsoon Wedding</td>\n",
       "      <td>7.3</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Black</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Deewaar</td>\n",
       "      <td>8</td>\n",
       "      <td>1975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name of movies Ratings Release Date\n",
       "0                     Ship of Theseus       8         2012\n",
       "1                              Iruvar     8.4         1997\n",
       "2                     Kaagaz Ke Phool     7.8         1959\n",
       "3   Lagaan: Once Upon a Time in India     8.1         2001\n",
       "4                     Pather Panchali     8.3         1955\n",
       "..                                ...     ...          ...\n",
       "95                        Apur Sansar     8.5         1959\n",
       "96                        Kanchivaram     8.1         2008\n",
       "97                    Monsoon Wedding     7.3         2001\n",
       "98                              Black     8.1         2005\n",
       "99                            Deewaar       8         1975\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "indian_Movie=BeautifulSoup(indian_Movie.content)\n",
    "\n",
    "\n",
    "\n",
    "movie_name = []\n",
    "\n",
    "row=indian_Movie.find_all('h3',class_=\"lister-item-header\")\n",
    "\n",
    "for i in row:\n",
    "    for f in i('a'):\n",
    "        movie_name.append(f.text)\n",
    "rating= []\n",
    "\n",
    "for i in indian_Movie.find_all('div',class_=\"ipl-rating-star small\"):\n",
    "    rating.append(i.text.replace('\\n',''))\n",
    "\n",
    "release_data=[]    \n",
    "    \n",
    "for i in indian_Movie.find_all('span',\"lister-item-year text-muted unbold\"):\n",
    "    release_data.append(i.text.replace(\"(\",\"\").replace(\")\",\"\"))\n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.DataFrame({\"name of movies\":movie_name,\"Ratings\":rating,\"Release Date\":release_data})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Write s python program to display list of respected former presidents of India(i.e. Name , Term of office) \n",
    "from https://presidentofindia.nic.in/former-presidents.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "president=requests.get(\"https://presidentofindia.nic.in/former-presidents.htm\")\n",
    "president"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>President_Name</th>\n",
       "      <th>Term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Ram Nath Kovind (birth - 1945)</td>\n",
       "      <td>Term of Office: 25 July, 2017 to 25 July, 2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Pranab Mukherjee (1935-2020)</td>\n",
       "      <td>Term of Office: 25 July, 2012 to 25 July, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smt Pratibha Devisingh Patil (birth - 1934)</td>\n",
       "      <td>Term of Office: 25 July, 2007 to 25 July, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam (1931-2015)</td>\n",
       "      <td>Term of Office: 25 July, 2002 to 25 July, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shri K. R. Narayanan (1920 - 2005)</td>\n",
       "      <td>Term of Office: 25 July, 1997 to 25 July, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dr Shankar Dayal Sharma (1918-1999)</td>\n",
       "      <td>Term of Office: 25 July, 1992 to 25 July, 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shri R Venkataraman (1910-2009)</td>\n",
       "      <td>Term of Office: 25 July, 1987 to 25 July, 1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Giani Zail Singh (1916-1994)</td>\n",
       "      <td>Term of Office: 25 July, 1982 to 25 July, 1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy (1913-1996)</td>\n",
       "      <td>Term of Office: 25 July, 1977 to 25 July, 1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed (1905-1977)</td>\n",
       "      <td>Term of Office: 24 August, 1974 to 11 February...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shri Varahagiri Venkata Giri (1894-1980)</td>\n",
       "      <td>Term of Office: 3 May, 1969 to 20 July, 1969 a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Zakir Husain (1897-1969)</td>\n",
       "      <td>Term of Office: 13 May, 1967 to 3 May, 1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan (1888-1975)</td>\n",
       "      <td>Term of Office: 13 May, 1962 to 13 May, 1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dr. Rajendra Prasad (1884-1963)</td>\n",
       "      <td>Term of Office: 26 January, 1950 to 13 May, 1962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 President_Name  \\\n",
       "0           Shri Ram Nath Kovind (birth - 1945)   \n",
       "1             Shri Pranab Mukherjee (1935-2020)   \n",
       "2   Smt Pratibha Devisingh Patil (birth - 1934)   \n",
       "3            DR. A.P.J. Abdul Kalam (1931-2015)   \n",
       "4            Shri K. R. Narayanan (1920 - 2005)   \n",
       "5           Dr Shankar Dayal Sharma (1918-1999)   \n",
       "6               Shri R Venkataraman (1910-2009)   \n",
       "7                  Giani Zail Singh (1916-1994)   \n",
       "8         Shri Neelam Sanjiva Reddy (1913-1996)   \n",
       "9          Dr. Fakhruddin Ali Ahmed (1905-1977)   \n",
       "10     Shri Varahagiri Venkata Giri (1894-1980)   \n",
       "11                 Dr. Zakir Husain (1897-1969)   \n",
       "12     Dr. Sarvepalli Radhakrishnan (1888-1975)   \n",
       "13             Dr. Rajendra Prasad (1884-1963)    \n",
       "\n",
       "                                                 Term  \n",
       "0     Term of Office: 25 July, 2017 to 25 July, 2022   \n",
       "1     Term of Office: 25 July, 2012 to 25 July, 2017   \n",
       "2     Term of Office: 25 July, 2007 to 25 July, 2012   \n",
       "3     Term of Office: 25 July, 2002 to 25 July, 2007   \n",
       "4     Term of Office: 25 July, 1997 to 25 July, 2002   \n",
       "5     Term of Office: 25 July, 1992 to 25 July, 1997   \n",
       "6     Term of Office: 25 July, 1987 to 25 July, 1992   \n",
       "7     Term of Office: 25 July, 1982 to 25 July, 1987   \n",
       "8     Term of Office: 25 July, 1977 to 25 July, 1982   \n",
       "9   Term of Office: 24 August, 1974 to 11 February...  \n",
       "10  Term of Office: 3 May, 1969 to 20 July, 1969 a...  \n",
       "11        Term of Office: 13 May, 1967 to 3 May, 1969  \n",
       "12       Term of Office: 13 May, 1962 to 13 May, 1967  \n",
       "13   Term of Office: 26 January, 1950 to 13 May, 1962  "
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "president_data=BeautifulSoup(president.content)\n",
    "\n",
    "raw=president_data.find_all(\"div\",class_=\"presidentListing\")\n",
    "\n",
    "Presidant_name = []\n",
    "\n",
    "for i in raw:\n",
    "    for j in i('h3'):\n",
    "        Presidant_name.append(j.text)\n",
    "\n",
    "term=[]\n",
    "for i in raw:\n",
    "    for f in i.find_all('p'):\n",
    "        term.append(f.text)\n",
    "        \n",
    "del term[1:9:2]  \n",
    "       \n",
    "  \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.DataFrame({\"Term\":term})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df1=pd.DataFrame({\"President_Name\":Presidant_name})\n",
    "\n",
    "result = pd.concat([df1,df],axis=1)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Write a python program to scrape cricket rankings from icc-cricket.com. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "mensrank=requests.get(\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\")\n",
    "mensrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "men=BeautifulSoup(mensrank.content)\n",
    "\n",
    "team=[]\n",
    "\n",
    "for i in men.find_all('span',class_=\"u-hide-phablet\"):\n",
    "    team.append(i.text)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI teams in men’s cricket :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>27</td>\n",
       "      <td>3,226</td>\n",
       "      <td>119               ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>22</td>\n",
       "      <td>2,508</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>31</td>\n",
       "      <td>3,447</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>22</td>\n",
       "      <td>2,354</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Australia</td>\n",
       "      <td>29</td>\n",
       "      <td>3,071</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>21</td>\n",
       "      <td>2,111</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>30</td>\n",
       "      <td>2,753</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>29</td>\n",
       "      <td>2,658</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>41</td>\n",
       "      <td>2,902</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>18</td>\n",
       "      <td>1,238</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Team Matches Points  \\\n",
       "1        England      27  3,226   \n",
       "2    New Zealand      22  2,508   \n",
       "3          India      31  3,447   \n",
       "4       Pakistan      22  2,354   \n",
       "5      Australia      29  3,071   \n",
       "6   South Africa      21  2,111   \n",
       "7     Bangladesh      30  2,753   \n",
       "8      Sri Lanka      29  2,658   \n",
       "9    West Indies      41  2,902   \n",
       "10   Afghanistan      18  1,238   \n",
       "\n",
       "                                               Rating  \n",
       "1                               119               ...  \n",
       "2                                                 114  \n",
       "3                                                 111  \n",
       "4                                                 107  \n",
       "5                                                 106  \n",
       "6                                                 101  \n",
       "7                                                  92  \n",
       "8                                                  92  \n",
       "9                                                  71  \n",
       "10                                                 69  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank1=[]\n",
    "\n",
    "for c in men.find_all('td',class_=\"rankings-block__banner--matches\"):\n",
    "    rank1.append(c.text)\n",
    "    \n",
    "pints1=[]    \n",
    "    \n",
    "for r in men.find_all('td',class_=\"rankings-block__banner--points\"):\n",
    "    pints1.append(r.text)    \n",
    "\n",
    "rtng=[]  \n",
    "\n",
    "for g in men.find_all('td',class_=\"rankings-block__banner--rating u-text-right\"):\n",
    "    rtng.append(g.text.replace('\\n','',))\n",
    "\n",
    "rtng1=[]\n",
    "\n",
    "for o in men.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    rtng1.append(o.text.replace('\\n','',))\n",
    "ratings=rtng+rtng1\n",
    "\n",
    "rank2=[]\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "for d in men.find_all('td',class_=\"table-body__cell u-center-text\"):\n",
    "    rank2.append(d.text)\n",
    "mtc=rank2[0:38:2]\n",
    "pints=rank2[1:38:2]\n",
    "\n",
    "matches=rank1+mtc\n",
    "points=pints1+pints\n",
    "\n",
    "df=pd.DataFrame({'Team':team,'Matches':matches,'Points':points,'Rating':ratings})\n",
    "print('Top 10 ODI teams in men’s cricket :')\n",
    "df.index = np.arange(1,len(df)+1)\n",
    "df.head(10)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Top 10 ODI Batsmen along with the records of their team and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "topbetsman=requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\")\n",
    "topbetsman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI batsmen :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>PAK</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Steve Smith</td>\n",
       "      <td>AUS</td>\n",
       "      <td>697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Player                     Team Ratings\n",
       "1              Babar Azam  PAK                         890\n",
       "2   Rassie van der Dussen                       SA     789\n",
       "3         Quinton de Kock                       SA     784\n",
       "4             Imam-ul-Haq                      PAK     779\n",
       "5             Virat Kohli                      IND     744\n",
       "6            Rohit Sharma                      IND     740\n",
       "7          Jonny Bairstow                      ENG     732\n",
       "8            David Warner                      AUS     725\n",
       "9             Ross Taylor                       NZ     701\n",
       "10            Steve Smith                      AUS     697"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=BeautifulSoup(topbetsman.content)\n",
    "\n",
    "plyr=[]\n",
    "\n",
    "for a in data.find_all('div',class_=\"rankings-block__banner--name-large\"):\n",
    "    plyr.append(a.text)\n",
    "            \n",
    "plyr1=[]\n",
    "\n",
    "for b in data.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "    plyr1.append(b.text.replace('\\n',''))\n",
    "    \n",
    "player=plyr+plyr1\n",
    "\n",
    "tm=[]\n",
    "\n",
    "for c in data.find_all('div',class_=\"rankings-block__banner--nationality\"):\n",
    "    tm.append(c.text.replace('\\n',''))\n",
    "    \n",
    "tm1=[] \n",
    "\n",
    "for d in data.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    tm1.append(d.text)\n",
    "\n",
    "team=tm+tm1    \n",
    " \n",
    "rtng=[]\n",
    "\n",
    "for e in data.find_all('div',class_=\"rankings-block__banner--rating\"):\n",
    "    rtng.append(e.text)\n",
    "    \n",
    "rtng1=[] \n",
    "\n",
    "for f in data.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    rtng1.append(f.text)\n",
    "\n",
    "rating=rtng+rtng1\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df=pd.DataFrame({'Player':player,'Team':team,'Ratings':rating})\n",
    "print('Top 10 ODI batsmen :')\n",
    "df.index = np.arange(1,len(df)+1)\n",
    "df.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "topbowlers=requests.get(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\")\n",
    "topbowlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI bowlers :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>PAK</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mohammad Nabi</td>\n",
       "      <td>AFG</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mitchell Starc</td>\n",
       "      <td>AUS</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Player                    Team Ratings\n",
       "1        Trent Boult  NZ                         775\n",
       "2     Josh Hazlewood                     AUS     718\n",
       "3   Mujeeb Ur Rahman                     AFG     676\n",
       "4     Jasprit Bumrah                     IND     662\n",
       "5     Shaheen Afridi                     PAK     661\n",
       "6      Mohammad Nabi                     AFG     657\n",
       "7       Mehedi Hasan                     BAN     655\n",
       "8         Matt Henry                      NZ     654\n",
       "9     Mitchell Starc                     AUS     653\n",
       "10       Rashid Khan                     AFG     651"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2=BeautifulSoup(topbowlers.content)\n",
    "\n",
    "plyr2=[]\n",
    "\n",
    "for m in data2.find_all('div',class_=\"rankings-block__banner--name-large\"):\n",
    "    plyr2.append(m.text)\n",
    "            \n",
    "plyr3=[]\n",
    "\n",
    "for n in data2.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "    plyr3.append(n.text.replace('\\n',''))\n",
    "    \n",
    "player1=plyr2+plyr3\n",
    "\n",
    "\n",
    "tm2=[]\n",
    "\n",
    "for c in data2.find_all('div',class_=\"rankings-block__banner--nationality\"):\n",
    "    tm2.append(c.text.replace('\\n',''))\n",
    "    \n",
    "tm3=[] \n",
    "\n",
    "for d in data2.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    tm3.append(d.text)\n",
    "\n",
    "team2=tm2+tm3\n",
    "\n",
    "rtng2=[]\n",
    "\n",
    "for e in data2.find_all('div',class_=\"rankings-block__banner--rating\"):\n",
    "    rtng2.append(e.text)\n",
    "    \n",
    "rtng3=[] \n",
    "\n",
    "for f in data2.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    rtng3.append(f.text)\n",
    "\n",
    "rating2=rtng2+rtng3\n",
    "\n",
    "df=pd.DataFrame({'Player':player1,'Team':team2,'Ratings':rating2})\n",
    "print('Top 10 ODI bowlers :')\n",
    "df.index = np.arange(1,len(df)+1)\n",
    "df.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#    # 6) Write a python program to scrape cricket rankings from icc-cricket.com.       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "womensrank=requests.get(\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\")\n",
    "womensrank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "women=BeautifulSoup(womensrank.content)\n",
    "\n",
    "wteam=[]\n",
    "\n",
    "for i in women.find_all('span',class_=\"u-hide-phablet\"):\n",
    "    wteam.append(i.text)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI teams in women’s cricket :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>29</td>\n",
       "      <td>4,837</td>\n",
       "      <td>167               ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>England</td>\n",
       "      <td>34</td>\n",
       "      <td>4,097</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>35</td>\n",
       "      <td>4,157</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>India</td>\n",
       "      <td>33</td>\n",
       "      <td>3,392</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>32</td>\n",
       "      <td>3,161</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>31</td>\n",
       "      <td>2,815</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>12</td>\n",
       "      <td>930</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>30</td>\n",
       "      <td>1,962</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>11</td>\n",
       "      <td>516</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>11</td>\n",
       "      <td>495</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Team Matches Points  \\\n",
       "1      Australia      29  4,837   \n",
       "2        England      34  4,097   \n",
       "3   South Africa      35  4,157   \n",
       "4          India      33  3,392   \n",
       "5    New Zealand      32  3,161   \n",
       "6    West Indies      31  2,815   \n",
       "7     Bangladesh      12    930   \n",
       "8       Pakistan      30  1,962   \n",
       "9        Ireland      11    516   \n",
       "10     Sri Lanka      11    495   \n",
       "\n",
       "                                               Rating  \n",
       "1                               167               ...  \n",
       "2                                                 121  \n",
       "3                                                 119  \n",
       "4                                                 103  \n",
       "5                                                  99  \n",
       "6                                                  91  \n",
       "7                                                  78  \n",
       "8                                                  65  \n",
       "9                                                  47  \n",
       "10                                                 45  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrank1=[]\n",
    "\n",
    "for c in women.find_all('td',class_=\"rankings-block__banner--matches\"):\n",
    "    wrank1.append(c.text)\n",
    "    \n",
    "wpints1=[]    \n",
    "    \n",
    "for r in women.find_all('td',class_=\"rankings-block__banner--points\"):\n",
    "    wpints1.append(r.text)    \n",
    "\n",
    "wrtng=[]  \n",
    "\n",
    "for g in women.find_all('td',class_=\"rankings-block__banner--rating u-text-right\"):\n",
    "    wrtng.append(g.text.replace('\\n','',))\n",
    "\n",
    "wrtng1=[]\n",
    "\n",
    "for o in women.find_all('td',class_=\"table-body__cell u-text-right rating\"):\n",
    "    wrtng1.append(o.text.replace('\\n','',))\n",
    "wratings=wrtng+wrtng1\n",
    "\n",
    "wrank2=[]\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "for d in women.find_all('td',class_=\"table-body__cell u-center-text\"):\n",
    "    wrank2.append(d.text)\n",
    "wmtc=wrank2[0:38:2]\n",
    "wpints=wrank2[1:38:2]\n",
    "\n",
    "wmatches=wrank1+wmtc\n",
    "wpoints=wpints1+wpints\n",
    "\n",
    "df=pd.DataFrame({'Team':wteam,'Matches':wmatches,'Points':wpoints,'Rating':wratings})\n",
    "print('Top 10 ODI teams in women’s cricket :')\n",
    "df.index = np.arange(1,len(df)+1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Top 10 women’s ODI Batting players along with the records of their team and rating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "wtopbetsman=requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\")\n",
    "wtopbetsman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI Women batsmen :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rachael Haynes</td>\n",
       "      <td>AUS</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Harmanpreet Kaur</td>\n",
       "      <td>IND</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chamari Athapaththu</td>\n",
       "      <td>SL</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Player                     Team Ratings\n",
       "1          Alyssa Healy  AUS                         785\n",
       "2           Beth Mooney                      AUS     749\n",
       "3        Natalie Sciver                      ENG     740\n",
       "4       Laura Wolvaardt                       SA     732\n",
       "5           Meg Lanning                      AUS     710\n",
       "6        Rachael Haynes                      AUS     701\n",
       "7       Smriti Mandhana                      IND     698\n",
       "8     Amy Satterthwaite                       NZ     681\n",
       "9      Harmanpreet Kaur                      IND     662\n",
       "10  Chamari Athapaththu                       SL     655"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wdata=BeautifulSoup(wtopbetsman.content)\n",
    "\n",
    "wplyr=[]\n",
    "\n",
    "for a in wdata.find_all('div',class_=\"rankings-block__banner--name-large\"):\n",
    "    wplyr.append(a.text)\n",
    "            \n",
    "wplyr1=[]\n",
    "\n",
    "for b in wdata.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "    wplyr1.append(b.text.replace('\\n',''))\n",
    "    \n",
    "wplayer=wplyr+wplyr1\n",
    "\n",
    "wtm=[]\n",
    "\n",
    "for c in wdata.find_all('div',class_=\"rankings-block__banner--nationality\"):\n",
    "    wtm.append(c.text.replace('\\n',''))\n",
    "    \n",
    "wtm1=[] \n",
    "\n",
    "for d in wdata.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    wtm1.append(d.text)\n",
    "\n",
    "wteam=wtm+wtm1    \n",
    " \n",
    "wrtng=[]\n",
    "\n",
    "for e in wdata.find_all('div',class_=\"rankings-block__banner--rating\"):\n",
    "    wrtng.append(e.text)\n",
    "    \n",
    "wrtng1=[] \n",
    "\n",
    "for f in wdata.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    wrtng1.append(f.text)\n",
    "\n",
    "wrating=wrtng+wrtng1\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df=pd.DataFrame({'Player':wplayer,'Team':wteam,'Ratings':wrating})\n",
    "print('Top 10 ODI Women batsmen :')\n",
    "df.index = np.arange(1,len(df)+1)\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "atopbetsman=requests.get(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\")\n",
    "atopbetsman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 ODI Womens Allrounder :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Team</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>WI</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>NZ</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jhulan Goswami</td>\n",
       "      <td>IND</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sophie Ecclestone</td>\n",
       "      <td>ENG</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Player                     Team Ratings\n",
       "1        Ellyse Perry  AUS                         374\n",
       "2      Natalie Sciver                      ENG     372\n",
       "3      Marizanne Kapp                       SA     349\n",
       "4     Hayley Matthews                       WI     339\n",
       "5         Amelia Kerr                       NZ     336\n",
       "6       Deepti Sharma                      IND     271\n",
       "7    Ashleigh Gardner                      AUS     270\n",
       "8       Jess Jonassen                      AUS     246\n",
       "9      Jhulan Goswami                      IND     219\n",
       "10  Sophie Ecclestone                      ENG     217"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata=BeautifulSoup(atopbetsman.content)\n",
    "\n",
    "aplyr=[]\n",
    "\n",
    "for a in adata.find_all('div',class_=\"rankings-block__banner--name-large\"):\n",
    "    aplyr.append(a.text)\n",
    "            \n",
    "aplyr1=[]\n",
    "\n",
    "for b in adata.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "    aplyr1.append(b.text.replace('\\n',''))\n",
    "    \n",
    "aplayer=aplyr+aplyr1\n",
    "\n",
    "atm=[]\n",
    "\n",
    "for c in adata.find_all('div',class_=\"rankings-block__banner--nationality\"):\n",
    "    atm.append(c.text.replace('\\n',''))\n",
    "    \n",
    "atm1=[] \n",
    "\n",
    "for d in adata.find_all('span',class_=\"table-body__logo-text\"):\n",
    "    atm1.append(d.text)\n",
    "\n",
    "ateam=atm+atm1    \n",
    " \n",
    "artng=[]\n",
    "\n",
    "for e in adata.find_all('div',class_=\"rankings-block__banner--rating\"):\n",
    "    artng.append(e.text)\n",
    "    \n",
    "artng1=[] \n",
    "\n",
    "for f in adata.find_all('td',class_=\"table-body__cell rating\"):\n",
    "    artng1.append(f.text)\n",
    "\n",
    "arating=artng+artng1\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df=pd.DataFrame({'Player':aplayer,'Team':ateam,'Ratings':arating})\n",
    "print('Top 10 ODI Womens Allrounder :')\n",
    "df.index = np.arange(1,len(df)+1)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "latestnews=requests.get(\"https://www.cnbc.com/world/?region=world\")\n",
    "latestnews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__________________HEADLINE___________________</th>\n",
       "      <th>__TIME__</th>\n",
       "      <th>__________________LINKS_________________</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trip.com says China hotel bookings are surpass...</td>\n",
       "      <td>9 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/22/tripcom-says-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2-year Treasury yield hovers around 4.1%, gap ...</td>\n",
       "      <td>13 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/22/2-year-treasur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Airline tickets could become even more expensi...</td>\n",
       "      <td>47 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/22/airline-ticket...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Russia arrests over 1,300 after Putin mobilize...</td>\n",
       "      <td>55 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/22/ukraine-war-ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amazon, Microsoft and Google face UK probe ove...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/22/uks-ofcom-prob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ukraine welcomes home 'heroes' after prisoner ...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/22/russia-ukraine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Swiss central bank hikes interest rate as infl...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/22/swiss-central-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The far-right is expected to win Italy's elect...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/22/italian-electi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Xpeng breaks out of a lower price range with i...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/22/xpeng-breaks-o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Turkey's lira hits new low as investors brace ...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/22/investors-brac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>European markets slide as investors digest mor...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/22/european-marke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The U.S. and allies are joining forces on chip...</td>\n",
       "      <td>7 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/22/semiconductor-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Outperforming fund manager reveals what he's b...</td>\n",
       "      <td>8 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/22/outperforming-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>'Boring is beautiful': Morgan Stanley's Wilson...</td>\n",
       "      <td>8 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/22/morgan-stanley...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The most common crime in UK hotels isn't theft</td>\n",
       "      <td>8 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/22/what-are-the-m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Yen pops on reports of direct intervention; As...</td>\n",
       "      <td>9 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/22/asia-markets-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Cramer's lightning round: Keep your powder dry...</td>\n",
       "      <td>10 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/21/cramers-lightn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>FTX in talks to raise up to $1 billion at flat...</td>\n",
       "      <td>10 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/21/ftx-in-talks-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Watch live: Ukrainian President Zelenskyy to a...</td>\n",
       "      <td>10 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/21/watch-uk-prime...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Investors betting short term will miss out whe...</td>\n",
       "      <td>10 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/21/investors-bett...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Marvell CEO tells Cramer: We're doing much bet...</td>\n",
       "      <td>10 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/21/marvell-ceo-te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Salesforce aims for 25% operating margin in 20...</td>\n",
       "      <td>11 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/21/salesforce-aim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Pro Picks: Watch all of Wednesday's big stock ...</td>\n",
       "      <td>11 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/21/pro-picks-watc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Stock futures inch up as traders weigh another...</td>\n",
       "      <td>11 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/21/stock-market-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Stocks making the biggest moves after hours: H...</td>\n",
       "      <td>12 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/21/stocks-making-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>GM to close reservations for electric Hummer p...</td>\n",
       "      <td>12 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/21/gm-to-close-re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Watch live: Ukrainian President Zelenskyy to a...</td>\n",
       "      <td>12 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/21/watch-ukrainia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Twitch announces ban on unlicensed gambling li...</td>\n",
       "      <td>12 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/21/twitch-announc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Read the highlights of the new lawsuit against...</td>\n",
       "      <td>12 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/21/trump-properti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3 of our stocks are in the news — here's our t...</td>\n",
       "      <td>12 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2022/09/21/investing-club...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        __________________HEADLINE___________________      __TIME__  \\\n",
       "1   Trip.com says China hotel bookings are surpass...     9 Min Ago   \n",
       "2   2-year Treasury yield hovers around 4.1%, gap ...    13 Min Ago   \n",
       "3   Airline tickets could become even more expensi...    47 Min Ago   \n",
       "4   Russia arrests over 1,300 after Putin mobilize...    55 Min Ago   \n",
       "5   Amazon, Microsoft and Google face UK probe ove...    1 Hour Ago   \n",
       "6   Ukraine welcomes home 'heroes' after prisoner ...    1 Hour Ago   \n",
       "7   Swiss central bank hikes interest rate as infl...    1 Hour Ago   \n",
       "8   The far-right is expected to win Italy's elect...   2 Hours Ago   \n",
       "9   Xpeng breaks out of a lower price range with i...   3 Hours Ago   \n",
       "10  Turkey's lira hits new low as investors brace ...   4 Hours Ago   \n",
       "11  European markets slide as investors digest mor...   4 Hours Ago   \n",
       "12  The U.S. and allies are joining forces on chip...   7 Hours Ago   \n",
       "13  Outperforming fund manager reveals what he's b...   8 Hours Ago   \n",
       "14  'Boring is beautiful': Morgan Stanley's Wilson...   8 Hours Ago   \n",
       "15     The most common crime in UK hotels isn't theft   8 Hours Ago   \n",
       "16  Yen pops on reports of direct intervention; As...   9 Hours Ago   \n",
       "17  Cramer's lightning round: Keep your powder dry...  10 Hours Ago   \n",
       "18  FTX in talks to raise up to $1 billion at flat...  10 Hours Ago   \n",
       "19  Watch live: Ukrainian President Zelenskyy to a...  10 Hours Ago   \n",
       "20  Investors betting short term will miss out whe...  10 Hours Ago   \n",
       "21  Marvell CEO tells Cramer: We're doing much bet...  10 Hours Ago   \n",
       "22  Salesforce aims for 25% operating margin in 20...  11 Hours Ago   \n",
       "23  Pro Picks: Watch all of Wednesday's big stock ...  11 Hours Ago   \n",
       "24  Stock futures inch up as traders weigh another...  11 Hours Ago   \n",
       "25  Stocks making the biggest moves after hours: H...  12 Hours Ago   \n",
       "26  GM to close reservations for electric Hummer p...  12 Hours Ago   \n",
       "27  Watch live: Ukrainian President Zelenskyy to a...  12 Hours Ago   \n",
       "28  Twitch announces ban on unlicensed gambling li...  12 Hours Ago   \n",
       "29  Read the highlights of the new lawsuit against...  12 Hours Ago   \n",
       "30  3 of our stocks are in the news — here's our t...  12 Hours Ago   \n",
       "\n",
       "             __________________LINKS_________________  \n",
       "1   https://www.cnbc.com/2022/09/22/tripcom-says-c...  \n",
       "2   https://www.cnbc.com/2022/09/22/2-year-treasur...  \n",
       "3   https://www.cnbc.com/2022/09/22/airline-ticket...  \n",
       "4   https://www.cnbc.com/2022/09/22/ukraine-war-ru...  \n",
       "5   https://www.cnbc.com/2022/09/22/uks-ofcom-prob...  \n",
       "6   https://www.cnbc.com/2022/09/22/russia-ukraine...  \n",
       "7   https://www.cnbc.com/2022/09/22/swiss-central-...  \n",
       "8   https://www.cnbc.com/2022/09/22/italian-electi...  \n",
       "9   https://www.cnbc.com/2022/09/22/xpeng-breaks-o...  \n",
       "10  https://www.cnbc.com/2022/09/22/investors-brac...  \n",
       "11  https://www.cnbc.com/2022/09/22/european-marke...  \n",
       "12  https://www.cnbc.com/2022/09/22/semiconductor-...  \n",
       "13  https://www.cnbc.com/2022/09/22/outperforming-...  \n",
       "14  https://www.cnbc.com/2022/09/22/morgan-stanley...  \n",
       "15  https://www.cnbc.com/2022/09/22/what-are-the-m...  \n",
       "16  https://www.cnbc.com/2022/09/22/asia-markets-f...  \n",
       "17  https://www.cnbc.com/2022/09/21/cramers-lightn...  \n",
       "18  https://www.cnbc.com/2022/09/21/ftx-in-talks-t...  \n",
       "19  https://www.cnbc.com/2022/09/21/watch-uk-prime...  \n",
       "20  https://www.cnbc.com/2022/09/21/investors-bett...  \n",
       "21  https://www.cnbc.com/2022/09/21/marvell-ceo-te...  \n",
       "22  https://www.cnbc.com/2022/09/21/salesforce-aim...  \n",
       "23  https://www.cnbc.com/2022/09/21/pro-picks-watc...  \n",
       "24  https://www.cnbc.com/2022/09/21/stock-market-f...  \n",
       "25  https://www.cnbc.com/2022/09/21/stocks-making-...  \n",
       "26  https://www.cnbc.com/2022/09/21/gm-to-close-re...  \n",
       "27  https://www.cnbc.com/2022/09/21/watch-ukrainia...  \n",
       "28  https://www.cnbc.com/2022/09/21/twitch-announc...  \n",
       "29  https://www.cnbc.com/2022/09/21/trump-properti...  \n",
       "30  https://www.cnbc.com/2022/09/21/investing-club...  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getdata=BeautifulSoup(latestnews.content)\n",
    "\n",
    "Headline=[]\n",
    "\n",
    "for i in getdata.find_all('a',class_=\"LatestNews-headline\"):\n",
    "    Headline.append(i.text)\n",
    "    \n",
    "Time=[]   \n",
    "\n",
    "for b in getdata.find_all('time',class_=\"LatestNews-timestamp\"):\n",
    "    Time.append(b.text)\n",
    "\n",
    "Links=[]\n",
    "\n",
    "for c in getdata.find_all('a',class_=\"LatestNews-headline\"):\n",
    "    Links.append(c['href'])\n",
    "    \n",
    "df=pd.DataFrame({'__________________HEADLINE___________________':Headline,'__TIME__':Time,'__________________LINKS_________________':Links})\n",
    "df.index = np.arange(1,len(df)+1)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Write a python program to scrape the details of most downloaded articles from AI in last 90 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "Access=requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Downloaded Articles :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Date</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Making sense of raw input</td>\n",
       "      <td>Evans, Richard, Bošnjak, Matko and 5 more</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Lemaignan, Séverin, Warnier, Mathieu and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Miller, Tim</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Making sense of sensory input</td>\n",
       "      <td>Evans, Richard, Hernández-Orallo, José and 3 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Sutton, Richard S., Precup, Doina, Singh, Sati...</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Bard, Nolan, Foerster, Jakob N. and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Argumentation in artificial intelligence</td>\n",
       "      <td>Bench-Capon, T.J.M., Dunne, Paul E.</td>\n",
       "      <td>October 2007</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Algorithms for computing strategies in two-pla...</td>\n",
       "      <td>Bošanský, Branislav, Lisý, Viliam and 3 more</td>\n",
       "      <td>August 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Luo, Wenhan, Xing, Junliang and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "      <td>Blum, Avrim L., Langley, Pat</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Arora, Saurabh, Doshi, Prashant</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Aas, Kjersti, Jullum, Martin, Løland, Anders</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Integrating social power into the decision-mak...</td>\n",
       "      <td>Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.</td>\n",
       "      <td>December 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>“That's (not) the output I expected!” On the r...</td>\n",
       "      <td>Riveiro, Maria, Thill, Serge</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Algorithm runtime prediction: Methods &amp; evalua...</td>\n",
       "      <td>Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...</td>\n",
       "      <td>January 2014</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Kohavi, Ron, John, George H.</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Commonsense visual sensemaking for autonomous ...</td>\n",
       "      <td>Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Quantum computation, quantum theory and AI</td>\n",
       "      <td>Ying, Mingsheng</td>\n",
       "      <td>February 2010</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "1                                    Reward is enough   \n",
       "2                           Making sense of raw input   \n",
       "3   Law and logic: A review from an argumentation ...   \n",
       "4              Creativity and artificial intelligence   \n",
       "5   Artificial cognition for social human–robot in...   \n",
       "6   Explanation in artificial intelligence: Insigh...   \n",
       "7                       Making sense of sensory input   \n",
       "8   Conflict-based search for optimal multi-agent ...   \n",
       "9   Between MDPs and semi-MDPs: A framework for te...   \n",
       "10  The Hanabi challenge: A new frontier for AI re...   \n",
       "11  Evaluating XAI: A comparison of rule-based and...   \n",
       "12           Argumentation in artificial intelligence   \n",
       "13  Algorithms for computing strategies in two-pla...   \n",
       "14      Multiple object tracking: A literature review   \n",
       "15  Selection of relevant features and examples in...   \n",
       "16  A survey of inverse reinforcement learning: Ch...   \n",
       "17  Explaining individual predictions when feature...   \n",
       "18  A review of possible effects of cognitive bias...   \n",
       "19  Integrating social power into the decision-mak...   \n",
       "20  “That's (not) the output I expected!” On the r...   \n",
       "21  Explaining black-box classifiers using post-ho...   \n",
       "22  Algorithm runtime prediction: Methods & evalua...   \n",
       "23              Wrappers for feature subset selection   \n",
       "24  Commonsense visual sensemaking for autonomous ...   \n",
       "25         Quantum computation, quantum theory and AI   \n",
       "\n",
       "                                              Authors            Date  \\\n",
       "1   Silver, David, Singh, Satinder, Precup, Doina,...    October 2021   \n",
       "2           Evans, Richard, Bošnjak, Matko and 5 more    October 2021   \n",
       "3                   Prakken, Henry, Sartor, Giovanni     October 2015   \n",
       "4                                 Boden, Margaret A.      August 1998   \n",
       "5     Lemaignan, Séverin, Warnier, Mathieu and 3 more       June 2017   \n",
       "6                                        Miller, Tim    February 2019   \n",
       "7   Evans, Richard, Hernández-Orallo, José and 3 more      April 2021   \n",
       "8   Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...   February 2015   \n",
       "9   Sutton, Richard S., Precup, Doina, Singh, Sati...     August 1999   \n",
       "10        Bard, Nolan, Foerster, Jakob N. and 13 more      March 2020   \n",
       "11  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...   February 2021   \n",
       "12               Bench-Capon, T.J.M., Dunne, Paul E.     October 2007   \n",
       "13       Bošanský, Branislav, Lisý, Viliam and 3 more     August 2016   \n",
       "14             Luo, Wenhan, Xing, Junliang and 4 more      April 2021   \n",
       "15                      Blum, Avrim L., Langley, Pat    December 1997   \n",
       "16                   Arora, Saurabh, Doshi, Prashant      August 2021   \n",
       "17      Aas, Kjersti, Jullum, Martin, Løland, Anders   September 2021   \n",
       "18  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...       June 2021   \n",
       "19    Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.    December 2016   \n",
       "20                      Riveiro, Maria, Thill, Serge   September 2021   \n",
       "21  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...        May 2021   \n",
       "22  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...    January 2014   \n",
       "23                      Kohavi, Ron, John, George H.    December 1997   \n",
       "24  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...    October 2021   \n",
       "25                                   Ying, Mingsheng    February 2010   \n",
       "\n",
       "                                                  Url  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  \n",
       "24  https://www.sciencedirect.com/science/article/...  \n",
       "25  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Articles=BeautifulSoup(Access.content)\n",
    "\n",
    "title=[]\n",
    "\n",
    "for i in Articles.find_all('h2',class_=\"sc-1qrq3sd-1 MKjKb sc-1nmom32-0 sc-1nmom32-1 hqhUYH ebTA-dR\"):\n",
    "    title.append(i.text)\n",
    "    \n",
    "authors=[]\n",
    "\n",
    "for e in Articles.find_all('span',class_='sc-1w3fpd7-0 pgLAT'):\n",
    "    authors.append(e.text)\n",
    "\n",
    "date=[]\n",
    "\n",
    "for c in Articles.find_all('span',class_='sc-1thf9ly-2 bKddwo'):\n",
    "    date.append(c.text)\n",
    "    \n",
    "url=[] \n",
    "\n",
    "for r in Articles.find_all('a',class_='sc-5smygv-0 nrDZj'):\n",
    "    url.append(r.get('href'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "    \n",
    "df=pd.DataFrame({'Title':title,'Authors':authors,'Date':date,'Url':url})\n",
    "print(\"Most Downloaded Articles :\")\n",
    "df.index=np.arange(1,len(df)+1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Write a python program to scrape mentioned details from dineout.co.in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "dine=requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "dine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Image URL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Restaurant Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Castle Barbeque</th>\n",
       "      <td>₹ 2,000 for 2 (approx) | Chinese, North Indian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jungle Jamboree</th>\n",
       "      <td>₹ 1,680 for 2 (approx) | North Indian, Asian, ...</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Castle Barbeque</th>\n",
       "      <td>₹ 2,000 for 2 (approx) | Chinese, North Indian</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cafe Knosh</th>\n",
       "      <td>₹ 3,000 for 2 (approx) | Italian, Continental</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Barbeque Company</th>\n",
       "      <td>₹ 1,700 for 2 (approx) | North Indian, Chinese...</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>India Grill</th>\n",
       "      <td>₹ 2,400 for 2 (approx) | North Indian, Italian</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delhi Barbeque</th>\n",
       "      <td>₹ 1,800 for 2 (approx) | North Indian</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>3.7</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Monarch - Bar Be Que Village</th>\n",
       "      <td>₹ 1,900 for 2 (approx) | North Indian</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indian Grill Room</th>\n",
       "      <td>₹ 2,200 for 2 (approx) | North Indian, Mughlai</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            Cuisine  \\\n",
       "Restaurant Name                                                                       \n",
       "Castle Barbeque                      ₹ 2,000 for 2 (approx) | Chinese, North Indian   \n",
       "Jungle Jamboree                   ₹ 1,680 for 2 (approx) | North Indian, Asian, ...   \n",
       "Castle Barbeque                      ₹ 2,000 for 2 (approx) | Chinese, North Indian   \n",
       "Cafe Knosh                            ₹ 3,000 for 2 (approx) | Italian, Continental   \n",
       "The Barbeque Company              ₹ 1,700 for 2 (approx) | North Indian, Chinese...   \n",
       "India Grill                          ₹ 2,400 for 2 (approx) | North Indian, Italian   \n",
       "Delhi Barbeque                                ₹ 1,800 for 2 (approx) | North Indian   \n",
       "The Monarch - Bar Be Que Village              ₹ 1,900 for 2 (approx) | North Indian   \n",
       "Indian Grill Room                    ₹ 2,200 for 2 (approx) | North Indian, Mughlai   \n",
       "\n",
       "                                                                           Location  \\\n",
       "Restaurant Name                                                                       \n",
       "Castle Barbeque                                      Connaught Place, Central Delhi   \n",
       "Jungle Jamboree                              3CS Mall,Lajpat Nagar - 3, South Delhi   \n",
       "Castle Barbeque                              Pacific Mall,Tagore Garden, West Delhi   \n",
       "Cafe Knosh                        The Leela Ambience Convention Hotel,Shahdara, ...   \n",
       "The Barbeque Company                             Gardens Galleria,Sector 38A, Noida   \n",
       "India Grill                                    Hilton Garden Inn,Saket, South Delhi   \n",
       "Delhi Barbeque                       Taurus Sarovar Portico,Mahipalpur, South Delhi   \n",
       "The Monarch - Bar Be Que Village  Indirapuram Habitat Centre,Indirapuram, Ghaziabad   \n",
       "Indian Grill Room                  Suncity Business Tower,Golf Course Road, Gurgaon   \n",
       "\n",
       "                                 Ratings  \\\n",
       "Restaurant Name                            \n",
       "Castle Barbeque                      4.1   \n",
       "Jungle Jamboree                      3.9   \n",
       "Castle Barbeque                      3.9   \n",
       "Cafe Knosh                           4.3   \n",
       "The Barbeque Company                   4   \n",
       "India Grill                          3.9   \n",
       "Delhi Barbeque                       3.7   \n",
       "The Monarch - Bar Be Que Village     3.8   \n",
       "Indian Grill Room                    4.3   \n",
       "\n",
       "                                                                          Image URL  \n",
       "Restaurant Name                                                                      \n",
       "Castle Barbeque                   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "Jungle Jamboree                   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "Castle Barbeque                   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "Cafe Knosh                        https://im1.dineout.co.in/images/uploads/resta...  \n",
       "The Barbeque Company              https://im1.dineout.co.in/images/uploads/resta...  \n",
       "India Grill                       https://im1.dineout.co.in/images/uploads/resta...  \n",
       "Delhi Barbeque                    https://im1.dineout.co.in/images/uploads/resta...  \n",
       "The Monarch - Bar Be Que Village  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "Indian Grill Room                 https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htl = BeautifulSoup(dine.content)\n",
    "\n",
    "name = []\n",
    "for i in htl.find_all('div',class_=\"restnt-info cursor\"):\n",
    "    for j in i.find_all('a',class_=\"restnt-name ellipsis\"):\n",
    "        name.append(j.text)\n",
    "cru = []\n",
    "for l in htl.find_all('div',class_=\"detail-info\"):\n",
    "    cru.append(l.text)\n",
    "loca = []\n",
    "for k in htl.find_all('div',class_=\"restnt-loc ellipsis\"):\n",
    "    loca.append(k.text)\n",
    "ratng = []\n",
    "for m in htl.find_all('div',class_=\"restnt-rating rating-4\"):\n",
    "    ratng.append(m.text)\n",
    "image= []\n",
    "for n in htl.find_all('img',class_=\"no-img\"):\n",
    "    image.append(n['data-src'])\n",
    "import pandas\n",
    "df =pandas.DataFrame({'Restaurant Name':name, 'Cuisine':cru, 'Location':loca, 'Ratings':ratng, 'Image URL':image})\n",
    "df1=df.set_index('Restaurant Name')\n",
    "df1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) Write a python program to scrape the details of top publications from Google Scholar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix=requests.get('https://scholar.google.com/citations?view_op=top_venues&hl=en')\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Publication</th>\n",
       "      <th>h5-index</th>\n",
       "      <th>h5-median</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.</th>\n",
       "      <td>Nature</td>\n",
       "      <td>444</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.</th>\n",
       "      <td>The New England Journal of Medicine</td>\n",
       "      <td>432</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.</th>\n",
       "      <td>Science</td>\n",
       "      <td>401</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.</th>\n",
       "      <td>IEEE/CVF Conference on Computer Vision and Pat...</td>\n",
       "      <td>389</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.</th>\n",
       "      <td>The Lancet</td>\n",
       "      <td>354</td>\n",
       "      <td>635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96.</th>\n",
       "      <td>Journal of Business Research</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97.</th>\n",
       "      <td>Molecular Cancer</td>\n",
       "      <td>145</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98.</th>\n",
       "      <td>Sensors</td>\n",
       "      <td>145</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99.</th>\n",
       "      <td>Nature Climate Change</td>\n",
       "      <td>144</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100.</th>\n",
       "      <td>IEEE Internet of Things Journal</td>\n",
       "      <td>144</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Publication h5-index h5-median\n",
       "Rank                                                                      \n",
       "1.                                               Nature      444       667\n",
       "2.                  The New England Journal of Medicine      432       780\n",
       "3.                                              Science      401       614\n",
       "4.    IEEE/CVF Conference on Computer Vision and Pat...      389       627\n",
       "5.                                           The Lancet      354       635\n",
       "...                                                 ...      ...       ...\n",
       "96.                        Journal of Business Research      145       233\n",
       "97.                                    Molecular Cancer      145       209\n",
       "98.                                             Sensors      145       201\n",
       "99.                               Nature Climate Change      144       228\n",
       "100.                    IEEE Internet of Things Journal      144       212\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load=BeautifulSoup(matrix.content)\n",
    "\n",
    "ranking=[]\n",
    "\n",
    "for i in load.find_all('td',class_=\"gsc_mvt_p\"):\n",
    "    ranking.append(i.text)\n",
    "pubn=[]\n",
    "for i in load.find_all('td',class_=\"gsc_mvt_t\"):\n",
    "    pubn.append(i.text)\n",
    "h5 = []\n",
    "for k in load.find_all('a',class_=\"gs_ibl gsc_mp_anchor\"):\n",
    "    h5.append(k.text)\n",
    "h5m = []\n",
    "for l in load.find_all('span',class_=\"gs_ibl gsc_mp_anchor\"):\n",
    "    h5m.append(l.text)\n",
    "import pandas as pan\n",
    "df = pan.DataFrame({'Rank':ranking, 'Publication':pubn, 'h5-index':h5, 'h5-median':h5m})\n",
    "df1=df.set_index('Rank')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
